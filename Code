import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

# Define the neural network architecture
class PINN(nn.Module):
    def __init__(self, layers):
        super(PINN, self).__init__()
        self.layers = nn.ModuleList()
        for i in range(len(layers) - 1):
            self.layers.append(nn.Linear(layers[i], layers[i + 1]))

    def forward(self, x):
        for i in range(len(self.layers) - 1):
            x = torch.tanh(self.layers[i](x))
        x = self.layers[-1](x)
        return x

# PDE loss function
def pde_loss(pinn_psi, pinn_theta, X, Ra):
    X.requires_grad_(True)
    psi = pinn_psi(X)
    theta = pinn_theta(X)

    # Gradients for psi
    psi_x = torch.autograd.grad(psi, X, torch.ones_like(psi), create_graph=True)[0][:, 0]
    psi_y = torch.autograd.grad(psi, X, torch.ones_like(psi), create_graph=True)[0][:, 1]
    psi_xx = torch.autograd.grad(psi_x, X, torch.ones_like(psi_x), create_graph=True)[0][:, 0]
    psi_yy = torch.autograd.grad(psi_y, X, torch.ones_like(psi_y), create_graph=True)[0][:, 1]

    # Gradients for theta
    theta_x = torch.autograd.grad(theta, X, torch.ones_like(theta), create_graph=True)[0][:, 0]
    theta_y = torch.autograd.grad(theta, X, torch.ones_like(theta), create_graph=True)[0][:, 1]
    theta_xx = torch.autograd.grad(theta_x, X, torch.ones_like(theta_x), create_graph=True)[0][:, 0]
    theta_yy = torch.autograd.grad(theta_y, X, torch.ones_like(theta_y), create_graph=True)[0][:, 1]

    tau = X[:, 2].view(-1, 1)
    theta_tau = torch.autograd.grad(theta, X, torch.ones_like(theta), create_graph=True)[0][:, 2]

    # PDE 1: d^2 psi / dx^2 + d^2 psi / dy^2 = - Ra * d theta / dx
    pde1 = psi_xx + psi_yy + Ra * theta_x

    # PDE 2: d theta / d tau + (psi_y * d theta / dx - psi_x * d theta / dy) = d^2 theta / dx^2 + d^2 theta / dy^2
    pde2 = theta_tau + psi_y * theta_x - psi_x * theta_y - (theta_xx + theta_yy)

    return torch.mean(pde1 ** 2), torch.mean(pde2 ** 2)

# Boundary loss function
def boundary_loss(pinn_psi, pinn_theta, X_bnd):
    X_bnd.requires_grad_(True)
    psi_bnd = pinn_psi(X_bnd)
    theta_bnd = pinn_theta(X_bnd)

    # Extract Y from the boundary points
    Y_vals = X_bnd[:, 1]

    # Apply boundary conditions for theta
    # Y=0 boundary: d(theta)/dy = -0.25
    theta_y_0 = torch.autograd.grad(theta_bnd, X_bnd, torch.ones_like(theta_bnd), create_graph=True)[0][:, 1]
    loss_bnd_theta_y0 = torch.mean((theta_y_0[Y_vals == 0] + 0) ** 2)

    # Y=1 boundary: d(theta)/dy = 0.25
    theta_y_1 = torch.autograd.grad(theta_bnd, X_bnd, torch.ones_like(theta_bnd), create_graph=True)[0][:, 1]
    loss_bnd_theta_y1 = torch.mean((theta_y_1[Y_vals == 1] - 0) ** 2)

    # Combine boundary losses
    loss_bnd_theta = loss_bnd_theta_y0 + loss_bnd_theta_y1

    # Placeholder boundary loss for psi (modify as per your specific boundary conditions for psi)
    loss_bnd_psi = torch.mean(psi_bnd ** 2)  # This is just a placeholder, modify as needed

    return loss_bnd_psi + loss_bnd_theta

# Initialize networks, optimizer, and constants
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

layers = [3, 50, 50, 50, 1]  # 3 input (X, Y, tau), several hidden, and 1 output (psi or theta)
pinn_psi = PINN(layers).to(device)
pinn_theta = PINN(layers).to(device)

optimizer = torch.optim.Adam(list(pinn_psi.parameters()) + list(pinn_theta.parameters()), lr=1e-3)

Ra = 1000.0  # Rayleigh number
epochs = 5000
batch_size = 100

# Generate training data for theta (X, Y, tau in range [0.000001, 1])
N_train = 1000
X_train_theta = np.random.uniform(0.000001, 1, (N_train, 3))  # Domain for theta
X_train_theta = torch.tensor(X_train_theta, dtype=torch.float32).to(device)

# Generate training data for psi (X, Y, tau in range [0.000001, 2])
X_train_psi = np.random.uniform(0.000001, 1, (N_train, 3))  # Extended domain for psi
X_train_psi = torch.tensor(X_train_psi, dtype=torch.float32).to(device)

# Training loop
for epoch in range(epochs):
    optimizer.zero_grad()

    # Randomly sample a batch for psi and theta
    idx_psi = np.random.choice(N_train, batch_size, replace=False)
    X_batch_psi = X_train_psi[idx_psi].clone().detach().requires_grad_(True)

    idx_theta = np.random.choice(N_train, batch_size, replace=False)
    X_batch_theta = X_train_theta[idx_theta].clone().detach().requires_grad_(True)

    # Calculate the PDE loss and boundary loss
    loss_pde1, loss_pde2 = pde_loss(pinn_psi, pinn_theta, X_batch_psi, Ra)
    loss_bnd = boundary_loss(pinn_psi, pinn_theta, X_batch_theta)

    # Total loss
    loss = loss_pde1 + loss_pde2 + loss_bnd
    loss.backward()
    optimizer.step()

    if epoch % 500 == 0:
        print(f'Epoch {epoch}, Loss: {loss.item():.6f}')

# After training, plot the contour for Psi and Theta at tau = 0.08
tau = 8

# Plot psi on the extended domain [0.000001, 2]
x_vals_psi = np.linspace(-2, 8, 100)
y_vals_psi = np.linspace(-2, 8, 100)
X_psi, Y_psi = np.meshgrid(x_vals_psi, y_vals_psi)
X_flat_psi = torch.tensor(X_psi.flatten(), dtype=torch.float32).to(device)
Y_flat_psi = torch.tensor(Y_psi.flatten(), dtype=torch.float32).to(device)
tau_flat_psi = torch.full_like(X_flat_psi, tau)

input_test_psi = torch.stack([X_flat_psi, Y_flat_psi, tau_flat_psi], dim=1).to(device)

# Get the predictions for psi
psi_pred = pinn_psi(input_test_psi).detach().cpu().numpy().reshape(X_psi.shape)

# Plot theta on the original domain [0.000001, 1]
x_vals_theta = np.linspace(-2, 8, 100)
y_vals_theta = np.linspace(-2, 8, 100)
X_theta, Y_theta = np.meshgrid(x_vals_theta, y_vals_theta)
X_flat_theta = torch.tensor(X_theta.flatten(), dtype=torch.float32).to(device)
Y_flat_theta = torch.tensor(Y_theta.flatten(), dtype=torch.float32).to(device)
tau_flat_theta = torch.full_like(X_flat_theta, tau)

input_test_theta = torch.stack([X_flat_theta, Y_flat_theta, tau_flat_theta], dim=1).to(device)

# Get the predictions for theta
theta_pred = pinn_theta(input_test_theta).detach().cpu().numpy().reshape(X_theta.shape)

# Plotting Psi and Theta contours
fig, axs = plt.subplots(1, 2, figsize=(12, 5))

# Psi contour on extended domain
contour_psi = axs[0].contour(X_psi, Y_psi, psi_pred, levels=50, cmap='viridis')
axs[0].clabel(contour_psi, inline=True, fontsize=8, fmt='%1.2f')  # Added clabel for Psi
axs[0].set_title('Psi Contour at Tau=0.08 (Extended Domain)')
axs[0].set_xlabel('X')
axs[0].set_ylabel('Y')

# Theta contour on original domain
contour_theta = axs[1].contour(X_theta, Y_theta, theta_pred, levels=50, cmap='inferno')
axs[1].clabel(contour_theta, inline=True, fontsize=8, fmt='%1.2f')  # Added clabel for Theta
axs[1].set_title('Theta Contour at Tau=0.08 (Original Domain)')
axs[1].set_xlabel('X')
axs[1].set_ylabel('Y')

plt.tight_layout()
plt.show()
